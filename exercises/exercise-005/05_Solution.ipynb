{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=False,\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY313,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe25a2c",
   "metadata": {},
   "source": [
    "# Solution to exercise set 5: Partial Least squares and training and testing.\n",
    "\n",
    "The main goals of this exercise are to perform Partial Least Squares (PLS) regression and use training and testing sets. Using training and testing sets allows us to assess the model's ability to generalize to unseen data and avoid overfitting. \n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "After completing this exercise set, you will be able to:\n",
    "\n",
    "- Create a PLS regression model.\n",
    "- Create and use training and test sets.\n",
    "- Assess your regression model by calculating root mean squared errors.\n",
    "\n",
    "**To get the exercise approved, complete the following problems:**\n",
    "\n",
    "* [5.1(a)](#5.1(a)), [5.1(b)](#5.1(b)), and [5.1(c)](#9.1(c)): To show that you can train a Partial Least Squares regression model and calculate RMSEC (Root Mean Squared Error of Calibration) and RMSEP (Root Mean Squared Error of Prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3b183",
   "metadata": {},
   "source": [
    "## Exercise 5.1 Partial Least Squares with training and testing\n",
    "\n",
    "[Windig and Stephenson](https://doi.org/10.1021/ac00046a015) measured near-infrared spectra\n",
    "for 140 mixtures of the solvents methylene chloride, 2-butanol, methanol,\n",
    "dichloropropane, and acetone. Here, we will predict the compositions of the mixtures from the spectra.\n",
    "Each spectrum was sampled at 700 wavelengths\n",
    "between 1100 and 2500 nm. The file\n",
    "[`windig.csv`](windig.csv) contains the raw data:\n",
    "Each row in this file\n",
    "contains a spectrum (the columns starting with `wavelength.`) and the\n",
    "corresponding concentrations (the columns starting with `conc.`).\n",
    "\n",
    "**The goal of exercise 5.1 is to make a model for predicting the composition of a mixture from its spectrum.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916009c",
   "metadata": {},
   "source": [
    "You can inspect the raw data by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"colorblind\")\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"windig.csv\")\n",
    "X = data.filter(like=\"wavelength\", axis=1).values  # NIR spectra\n",
    "Y = data.filter(like=\"conc\", axis=1).values  # Concentrations\n",
    "print(f\"No. of spectra: {X.shape[0]}\")\n",
    "print(f\"No. of wavelengths: {X.shape[1]}\")\n",
    "print(f\"No of concentration samples: {Y.shape[0]}\")\n",
    "print(f\"No of species in each sample: {Y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bed7b6",
   "metadata": {},
   "source": [
    "And the individual spectra can be visualised with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the spectra:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "for spectrum in X:\n",
    "    ax.plot(spectrum)\n",
    "ax.set(xlabel=\"Wavelength (nm)\", ylabel=\"Absorbance\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8db3d",
   "metadata": {},
   "source": [
    "**Note:** The spectra have been processed so you can use the directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0cd7f",
   "metadata": {},
   "source": [
    "### 5.1(a)\n",
    "\n",
    "To develop and assess your model, you will create and make use of a training and testing data set.\n",
    "\n",
    "**Explain what the purposes of these two sets are and how they can be created.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963b6df",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.1(a): What is the purpose of the training and testing data sets, and how are they created?\n",
    "\n",
    "The training set is used to train the model, while the testing set evaluates its performance on unseen samples, testing its ability to generalize. These sets are created by randomly splitting the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45e9d9",
   "metadata": {},
   "source": [
    "### 5.1(b)\n",
    "\n",
    "**Split the raw data into a training set and a test set. Use 33% of the data for the test set. How many samples do you have in the training set and the test set?**\n",
    "\n",
    "**Hint:** With scikit-learn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), splitting the data can be done with\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.33,  # Use 33 % of the data (one-third) for the test set.\n",
    "    shuffle=True,  # Randomly shuffle the data\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.33,  # Use 33 % of the data (one-third) for the test set.\n",
    "    shuffle=True,  # Randomly shuffle the data\n",
    "    random_state=2025,  # To get the same splits every time we run this\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02475ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1faa24",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.1(b): How many samples do you have in the training set and the test set?\n",
    "\n",
    "There are 93 samples in the training set and 47 samples in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a78abe",
   "metadata": {},
   "source": [
    "### 5.1(c)\n",
    "\n",
    "**Task: Create a Partial Least Squares (PLS) regression model for predicting the concentrations from the spectra. Use 2 latent variables for the PLS model and evaluate your model by calculating the RMSEC (root mean squared error of calibration) and RMSEP (root mean squared error of prediction) for each of the five concentrations.**\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1.  **Create a PLS regression model:**\n",
    "    ```python\n",
    "    from sklearn.cross_decomposition import PLSRegression\n",
    "    # Set up a PLS model:\n",
    "    model = PLSRegression(\n",
    "        n_components=2,  # Use two components (latent variables)\n",
    "        scale=False,  # Do not scale X and Y (we will do this separately, if needed)\n",
    "    )\n",
    "    ```\n",
    "\n",
    "2.  **Fit the model to the training data:**\n",
    "    ```python\n",
    "    model.fit(X_train, Y_train)  # Fit/make the model\n",
    "    ```\n",
    "\n",
    "3.  **Calculate the RMSEC (root mean squared error of calibration):**\n",
    "    * When we use the training set to create our model, we are doing a *calibration*. If we calculate the RMSE (root mean squared error) based on the training set, we refer to this as the RMSEC. This quantifies the error we get in connection with making (calibrating) the model.\n",
    "    ```python\n",
    "    from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    rmsec = root_mean_squared_error(Y_train, y_hat_train)\n",
    "    ```\n",
    "\n",
    "4.  **Calculate the RMSEP (root mean squared error of prediction):**\n",
    "    * When we use the test set to test our model, we are checking how well our model *predicts* \"new\" samples (that is, samples not used when making the model). If we calculate RMSE based on the test set, we refer to this as the RMSEP. This quantifies the error we can expect to make when using our model for predicting new samples.\n",
    "    ```python\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    rmsep = root_mean_squared_error(Y_test, y_hat_test)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604150f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "model = PLSRegression(\n",
    "    n_components=2, scale=False\n",
    ")  # Set up a PLS model with 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "rmsec = root_mean_squared_error(Y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = model.predict(X_test)\n",
    "rmsep = root_mean_squared_error(Y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cdd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSEC = {rmsec:.3g}\")\n",
    "print(f\"RMSEP = {rmsep:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison, Y is:\n",
    "print(f\"Mean (Y) = {np.mean(Y, axis=0)}\")\n",
    "print(f\"Min (Y) = {np.min(Y, axis=0)}\")\n",
    "print(f\"Max (Y) = {np.max(Y, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec63e3",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.1(c): What values did you get for RMSEC and RMSEP.\n",
    "\n",
    "The RMSEC and RMSEP are printed above. They are comparable to the smallest concentrations, so the errors are quite large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6c9b4",
   "metadata": {},
   "source": [
    "### 5.1(d)\n",
    "\n",
    "**Task: Optimize the number of PLS components by performing cross-validation on a grid where you vary the number of components. Calculate RMSEC, RMSECV (root mean squared error of cross-validation), and RMSEP for your new model. Report the optimal number of components.**\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. **Optimize the number of components by using cross-validation on a grid of possible parameters, for instance, by using [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for scikit-learn:**\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\"n_components\": range(1, 11)}  # Test 1 through 10 components\n",
    "# Set up a search over the parameter space:\n",
    "grid_search = GridSearchCV(\n",
    "    PLSRegression(scale=False),  # The base model\n",
    "    parameters,  # The parameters we will consider,\n",
    "    cv=5,  # The number of splits for the cross-validation\n",
    "    scoring=\"neg_mean_squared_error\",  # How we score how well the model is performing\n",
    "    refit=True,  # Refit using the best-found parameters on the whole training set.\n",
    ")\n",
    "# Run the cross-validation\n",
    "grid_search.fit(X_train, Y_train)\n",
    "# Get the best number of components:\n",
    "best_components = grid_search.best_params_[\"n_components\"]\n",
    "# Get the best-performing model:\n",
    "best_model = grid_search.best_estimator_\n",
    "# Get the results per parameter considered:\n",
    "mean_score = grid_search.cv_results_[\"mean_test_score\"]  # The mean score\n",
    "error_score = grid_search.cv_results_[\n",
    "    \"std_test_score\"\n",
    "]  # The uncertainty in the score\n",
    "# These two can be plotted as a function of the number of parameters considered;\n",
    "# this can help us see the best parameters while considering the error.\n",
    "```\n",
    "\n",
    "2. **Recalculate RMSECV using the optimized model, for instance, by using [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) from scikit-learn:**\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cvscore = cross_val_score(\n",
    "    model,  # Select the model we are going to score\n",
    "    X_train,  # Give the X-training set\n",
    "    Y_train,  # Give the y-training set\n",
    "    scoring=\"neg_mean_squared_error\",  # select scoring method\n",
    "    cv=5,  # Number of splits to make\n",
    ")\n",
    "cvscore = np.sqrt(-cvscore)  # Account for the negative sign.\n",
    "rmsecv = cvscore.mean()\n",
    "rmsecv_std = np.std(cvscore)\n",
    "print(f\"\\nRMSECV: {rmsecv} ± {rmsecv_std}\")\n",
    "```\n",
    "\n",
    "**Note:** We use a *negative* mean squared error for the grid search and for calculating RMSECV. This is because the methods `cross_val_score` and `GridSearchCV` are often used in connection with optimization where we want to *maximize* something. If we *maximize the negative* of the mean squared error, we can *minimize the error*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\"n_components\": range(1, 21)}  # Test 1 through 20 components\n",
    "# Set up a search over the parameter space:\n",
    "grid_search = GridSearchCV(\n",
    "    PLSRegression(scale=False),  # The base model\n",
    "    parameters,  # The parameters we will consider,\n",
    "    cv=5,  # The number of splits for the cross-validation\n",
    "    scoring=\"neg_mean_squared_error\",  # How we score how well the model is performing\n",
    "    refit=True,  # Refit using the best-found parameters on the whole training set.\n",
    ")\n",
    "# Run the cross-validation\n",
    "grid_search.fit(X_train, Y_train)\n",
    "# Get the best number of components:\n",
    "best_components = grid_search.best_params_[\"n_components\"]\n",
    "# Get the best-performing model:\n",
    "best_model = grid_search.best_estimator_\n",
    "# Get the results per parameter considered:\n",
    "mean_score = grid_search.cv_results_[\"mean_test_score\"]  # The mean score\n",
    "error_score = grid_search.cv_results_[\n",
    "    \"std_test_score\"\n",
    "]  # The uncertainty in the score\n",
    "print(f\"Best components: {best_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    constrained_layout=True, ncols=2, sharex=True, figsize=(8, 4)\n",
    ")\n",
    "ax1.errorbar(\n",
    "    parameters[\"n_components\"], mean_score, yerr=error_score, marker=\"o\"\n",
    ")\n",
    "ax2.errorbar(\n",
    "    parameters[\"n_components\"][3:],\n",
    "    mean_score[3:],\n",
    "    yerr=error_score[3:],\n",
    "    marker=\"o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00752eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pls_optimized = PLSRegression(n_components=6, scale=False)\n",
    "pls_optimized.fit(X_train, Y_train)\n",
    "\n",
    "cvscore = cross_val_score(\n",
    "    pls_optimized,  # Select the model we are going to score\n",
    "    X_train,  # Give the X-training set\n",
    "    Y_train,  # Give the y-training set\n",
    "    scoring=\"neg_mean_squared_error\",  # select scoring method\n",
    "    cv=5,  # Number of splits to make\n",
    ")\n",
    "cvscore = np.sqrt(-cvscore)  # Account for the negative sign.\n",
    "rmsecv = cvscore.mean()\n",
    "rmsecv_std = np.std(cvscore)\n",
    "print(f\"\\nRMSECV: {rmsecv} ± {rmsecv_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7a493",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.1(d): What is the optimal number of components?\n",
    "\n",
    "While grid search yielded 21 components, analysis of the mean squared error suggests diminishing returns beyond 6-7 components. To prioritize model simplicity, we select 6 components as the optimal number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1963d89",
   "metadata": {},
   "source": [
    "### 5.1(e)\n",
    "\n",
    "**Task: Show the results for the training data and the testing data graphically by plotting the predicted vs. the observed values for all 5 chemical components for the optimized model. Include RMSEC, R² for the training set, RMSEP and R² for the test set as labels in your figure (calculate these for each component separately). Further, report the metrics you calculated in a table.**\n",
    "\n",
    "**Hint:** The R² can be calculated using:\n",
    "```python\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "component_number = 1  # To select a column (one component) from Y:\n",
    "r_squared_train = r2_score(Y_train[:,component_number], y_predicted_train[:,component_number])\n",
    "r_squared_test = r2_score(Y_test[:,component_number], y_predicted_test[:,component_number])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = pls_optimized.predict(X_train)\n",
    "Y_hat_test = pls_optimized.predict(X_test)\n",
    "\n",
    "components = [\n",
    "    \"methylene chloride\",\n",
    "    \"2-butanol\",\n",
    "    \"methanol\",\n",
    "    \"dichloropropane\",\n",
    "    \"acetone\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    ncols=3,\n",
    "    nrows=2,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    figsize=(10, 6),\n",
    ")\n",
    "axes = axes.flatten()\n",
    "axes_used = []\n",
    "\n",
    "table = {\n",
    "    \"Component\": [],\n",
    "    \"RMSEC\": [],\n",
    "    \"RMSEP\": [],\n",
    "    \"R² (train)\": [],\n",
    "    \"R² (test)\": [],\n",
    "}\n",
    "\n",
    "for i, component in enumerate(components):\n",
    "    r_squared_train = r2_score(Y_train[:, i], Y_hat_train[:, i])\n",
    "    rmse_train = root_mean_squared_error(Y_train[:, i], Y_hat_train[:, i])\n",
    "\n",
    "    r_squared_test = r2_score(Y_test[:, i], Y_hat_test[:, i])\n",
    "    rmse_test = root_mean_squared_error(Y_test[:, i], Y_hat_test[:, i])\n",
    "\n",
    "    table[\"Component\"].append(component)\n",
    "    table[\"RMSEC\"].append(rmse_train)\n",
    "    table[\"RMSEP\"].append(rmse_test)\n",
    "    table[\"R² (train)\"].append(r_squared_train)\n",
    "    table[\"R² (test)\"].append(r_squared_test)\n",
    "\n",
    "    txt_train = f\"R² (train) = {r_squared_train:.2f}\\nRMSEC = {rmse_train:.2f}\"\n",
    "    txt_test = f\"R² (test) = {r_squared_test:.2f}\\nRMSEP = {rmse_test:.2f}\"\n",
    "\n",
    "    axes[i].scatter(Y_train[:, i], Y_hat_train[:, i], label=txt_train)\n",
    "    axes[i].scatter(Y_test[:, i], Y_hat_test[:, i], label=txt_test)\n",
    "\n",
    "    axes[i].set_xlabel(\"Observed (y)\")\n",
    "    axes[i].set_ylabel(\"Predicted (ŷ)\")\n",
    "    axes[i].set_title(f\"{component}\", loc=\"left\")\n",
    "    axes[i].legend()\n",
    "\n",
    "    xaxis = axes[i].get_xlim()\n",
    "    yaxis = axes[i].get_ylim()\n",
    "\n",
    "    imin = min(xaxis + yaxis)\n",
    "    imax = max(xaxis + yaxis)\n",
    "\n",
    "    axes[i].plot([imin, imax], [imin, imax], ls=\":\", color=\"k\")\n",
    "    axes[i].set_xlim(xaxis)\n",
    "    axes[i].set_ylim(yaxis)\n",
    "\n",
    "    axes_used.append(axes[i])\n",
    "\n",
    "for ax in axes:\n",
    "    if ax not in axes_used:\n",
    "        ax.axis(\"off\")\n",
    "sns.despine(fig=fig)\n",
    "fig.savefig(\"5.1.e.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41039d3",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.1(e): Report the metrics you found:\n",
    "\n",
    "The evaluation metrics, as presented in the table above. The RMSEP, consistently below 1, signifies a prediction error within 10% of the minimum concentration, suggesting good accuracy across the concentration range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febcce0",
   "metadata": {},
   "source": [
    "## Exercise 5.2 Use of cross-validation when we have few samples\n",
    "\n",
    "It is not always feasible to do the split into training and test sets when we have few samples. Another option then is to use something called **Leave-one-out cross-validation** (LOOCV). LOOCV involves training the model on all but one data point and using the remaining point for testing, repeating this process for each data point. We will use that method in this exercise\n",
    "\n",
    "We will use the data of [Forbes](https://doi.org/10.1017/S0080456800032075) who investigated the\n",
    "relationship between the boiling point of water and the atmospheric pressure, and collected data in the Alps and Scotland. Forbes' goal was to estimate altitudes from the boiling point alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119b5e6",
   "metadata": {},
   "source": [
    "### 5.2(a)\n",
    "\n",
    "**Task: Load the data from Forbes (data file [forbes.csv](forbes.csv)), plot it, and create a linear regression model\n",
    "that predicts the atmospheric pressure from the temperature. Report the R² and [root mean\n",
    "squared error (RMSE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html) for your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forbes = pd.read_csv(\"forbes.csv\")\n",
    "forbes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55608e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_forbes = forbes[\"Temperature (F)\"].to_numpy().reshape(-1, 1)\n",
    "y_forbes = forbes[\"Pressure (inches Hg)\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb91144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeed326",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forbes = LinearRegression(fit_intercept=True)\n",
    "model_forbes.fit(X_forbes, y_forbes)\n",
    "y_hat_forbes = model_forbes.predict(X_forbes)\n",
    "\n",
    "r2_forbes = r2_score(y_forbes, y_hat_forbes)\n",
    "rmse_forbes = root_mean_squared_error(y_forbes, y_hat_forbes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dedfbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "sns.scatterplot(\n",
    "    data=forbes,\n",
    "    x=\"Temperature (F)\",\n",
    "    y=\"Pressure (inches Hg)\",\n",
    "    label=\"Raw data\",\n",
    "    s=100,\n",
    ")\n",
    "\n",
    "X_eval = np.row_stack([min(X_forbes), max(X_forbes)])\n",
    "y_eval = model_forbes.predict(X_eval)\n",
    "\n",
    "\n",
    "text = f\"ŷ = {model_forbes.intercept_:.3g} + {model_forbes.coef_[0]:.3g}x\"\n",
    "text = f\"{text}\\n(R² = {r2_forbes:.3g}, RMSE = {rmse_forbes:.3g})\"\n",
    "\n",
    "ax.plot([], [])  # To cycle colors\n",
    "ax.plot(\n",
    "    X_eval.flatten(),\n",
    "    y_eval.flatten(),\n",
    "    label=text,\n",
    ")\n",
    "ax.legend()\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a15fc",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.2(a): What value did you get for R² and the RMSE?\n",
    "\n",
    "The model is shown in the figure above. R² as 0.99 and the RMSE was 0.22."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a29e4a",
   "metadata": {},
   "source": [
    "### 5.2(b)\n",
    "\n",
    "**Task: Estimate the error you can expect to make if you use your model for predicting the pressure.\n",
    "Do this by LOOCV and calculate the root mean squared error of cross-validation (RMSECV)**\n",
    "\n",
    "**Note:** LOOCV is a special case of **training** and **testing**, and you can find a short description of it\n",
    "in [appendix A](#A.-Leave-one-out-cross-validation) with example code for running LOOCV. The code example for LOOCV is concise, so make sure you understand what goes on here (that is, what LOOCV is doing). If you are working with someone, try explaining testing/training and how LOOCV works to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1:\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "error = []\n",
    "# Split the X-data in X_temp into training and testing:\n",
    "for train_index, test_index in loo.split(X_forbes):\n",
    "    X_train, X_test = X_forbes[train_index], X_forbes[test_index]\n",
    "    y_train, y_test = y_forbes[train_index], y_forbes[test_index]\n",
    "    # Fit a new model with the training set:\n",
    "    model = LinearRegression(fit_intercept=True).fit(X_train, y_train)\n",
    "    # Predict y for the test set:\n",
    "    y_hat = model.predict(X_test)\n",
    "    # Compare the predicted y values in the test set with the measured ones:\n",
    "    error.append((y_test - y_hat) ** 2)\n",
    "rmsecv_1 = np.sqrt(np.mean(error))\n",
    "print(f\"RMSECV = {rmsecv_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2:\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "scores = cross_val_score(\n",
    "    model,\n",
    "    X_forbes,\n",
    "    y_forbes,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=LeaveOneOut(),\n",
    ")\n",
    "rmsecv_2 = np.sqrt(np.mean(-scores))\n",
    "print(f\"RMSECV = {rmsecv_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23afd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3:\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "x = forbes[\"Temperature (F)\"].to_numpy()\n",
    "model.fit(x.reshape(-1, 1), y_forbes)\n",
    "y_hat_forbes = model.predict(x.reshape(-1, 1))\n",
    "\n",
    "X_matrix = np.column_stack((np.ones_like(x), x))\n",
    "H = X_matrix @ np.linalg.pinv(X_matrix)\n",
    "hii = np.diagonal(H)\n",
    "residuals_loo = (y_forbes - y_hat_forbes) / (1 - hii)\n",
    "rmsecv_3 = np.sqrt(np.mean(residuals_loo**2))\n",
    "print(f\"RMSECV = {rmsecv_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fbdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmsecv_1, rmsecv_1 / rmsecv_2, rmsecv_1 / rmsecv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e94306",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=forbes,\n",
    "    x=\"Temperature (F)\",\n",
    "    y=\"Pressure (inches Hg)\",\n",
    "    label=\"Raw data\",\n",
    "    s=100,\n",
    ")\n",
    "\n",
    "X_eval = np.row_stack([min(X_forbes), max(X_forbes)])\n",
    "y_eval = model_forbes.predict(X_eval)\n",
    "\n",
    "\n",
    "upper = y_eval + rmsecv_1\n",
    "lower = y_eval - rmsecv_1\n",
    "\n",
    "\n",
    "text = f\"ŷ = {model_forbes.intercept_:.3g} + {model_forbes.coef_[0]:.3g}x\"\n",
    "text = f\"{text}\\n(R² = {r2_forbes:.3g}, RMSE = {rmse_forbes:.3g})\"\n",
    "\n",
    "ax.plot([], [])  # To cycle colors\n",
    "ax.plot(\n",
    "    X_eval.flatten(),\n",
    "    y_eval.flatten(),\n",
    "    label=text,\n",
    ")\n",
    "\n",
    "\n",
    "ax.plot(X_eval.flatten(), upper, label=f\"ŷ + RMSECV ({rmsecv_1:.2g})\", ls=\":\")\n",
    "ax.plot(X_eval.flatten(), lower, label=f\"ŷ - RMSECV ({rmsecv_1:.2g})\", ls=\"--\")\n",
    "\n",
    "ax.legend()\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c5e02",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.2(b): What value did you get for RMSECV?\n",
    "\n",
    "The RMSECV was 0.24. It is only slightly bigger than the RMSE previously calculated. Importantly, this value is significantly smaller than the observed pressure range of 20-30 inches Hg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5d263f",
   "metadata": {},
   "source": [
    "## Exercise 5.3 Partial Least Squares and interpretation of scores and loadings\n",
    "\n",
    "The file [elements.csv](elements.csv) contains information about the elements of the periodic table. This dataset includes various physical and chemical properties, allowing us to explore the underlying relationships between these elements. The columns in the file are as follows:\n",
    "\n",
    "\n",
    "| **Column**                      | **Description**                                         | **Unit** |\n",
    "|:--------------------------------|:--------------------------------------------------------|:---------|\n",
    "| name                            | The name of the element                                 |          |\n",
    "| symbol                          | The symbol for the element (e.g. H, He, etc.)           |          |\n",
    "| atomic_radius                   | Atomic radius                                           | Å        |\n",
    "| atomic_weight                   | Atomic weight                                           | u        |\n",
    "| covalent_radius                 | Covalent radius                                         | pm       |\n",
    "| density                         | Density at 295 K                                        | g/cm³    |\n",
    "| dipole_polarizability           | Dipole polarizability                                   | bohr³    |\n",
    "| electrons                       | The number of electrons in the element                  |          |\n",
    "| mass_number                     | Mass number of the most abundant isotope                |          |\n",
    "| neutrons                        | The number of neutrons in the element                   |          |\n",
    "| protons                         | The number of protons in the element                    |          |\n",
    "| zeff                            | Effective nuclear charge                                |          |\n",
    "| vdw_radius                      | Van der Waals radius                                    | pm       |\n",
    "| first_ionization                | First ionization energy                                 | eV       |\n",
    "| electronegativity allred-rochow | Allred and Rochow’s scale of electronegativity          | e²/pm²   |\n",
    "| electronegativity gordy         | Gordy’s scale of electronegativity                      | e/pm     | \n",
    "| atomic_radius_wikipedia         | Atomic radius from [Wikipedia](https://en.wikipedia.org/wiki/Atomic_radii_of_the_elements_(data_page)) | pm |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905e637",
   "metadata": {},
   "source": [
    "### 5.3(a)\n",
    "\n",
    "**Task: Create a PLS regression model for predicting `first_ionization`, `density`, `protons`, and `atomic_radius` from the other variables.**\n",
    "\n",
    "**Notes:**:\n",
    "\n",
    "1. Remove the non-numeric columns like 'name' and 'symbol' before creating the PLS model.\n",
    "\n",
    "2. Use two components for the PLS regression model. Do not do a split into a training and test set in this exercise (this is not so crucial here since we will focus on interpreting scores and loadings).\n",
    "\n",
    "3. Consider if you should normalize (scale) the data using a [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) before performing the PLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d23c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic = pd.read_csv(\"elements.csv\")\n",
    "periodic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce10a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = [\"name\", \"symbol\"]\n",
    "\n",
    "y_vars = [\"first_ionization\", \"density\", \"protons\", \"atomic_radius\"]\n",
    "x_vars = [i for i in periodic.columns if i not in skip and i not in y_vars]\n",
    "print(x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_raw = periodic[y_vars].to_numpy()\n",
    "X_raw = periodic[x_vars].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have different units, we scale:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_peri = StandardScaler().fit_transform(X_raw)\n",
    "Y_peri = StandardScaler().fit_transform(Y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_periodic = PLSRegression(n_components=2, scale=False)\n",
    "pls_periodic.fit(X_peri, Y_peri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53024d8e",
   "metadata": {},
   "source": [
    "### 5.3(b)\n",
    "\n",
    "**Task: Inspect the scores and rotations for X by creating 2D scatter plots. Are there any trends/groupings or outliers in the scores? What of the original X-variables can, if groups/trends are present, be used to interpret these trends?**\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. Assuming that `pls` is the fitted object containing the PLS model, and `X` is our raw data, we can get the scores and rotations by:\n",
    "```python\n",
    "x_scores = pls.transform(X)\n",
    "x_rotations = pls.x_rotations_\n",
    "```\n",
    "\n",
    "2. For the scatter plots, you have two options. To plot the scores and rotations for the two PLS components in two different plots, or in the same plot (as a biplot). The biplot can sometimes help interpretation, but can be crowded if there are many samples and features.\n",
    "\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "1. We use the rotations here instead of the loadings (or weights). This is because the X-rotations apply directly to the X data to create the scores. Thus, the rotations tell use more directly the relation between the original variables and the calculated scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scores = pls_periodic.transform(X_peri)\n",
    "x_rotations = pls_periodic.x_rotations_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9733b634",
   "metadata": {},
   "source": [
    "For added interpretation, let us color according to the period. We collect information about the group from the Python package [mendeleev](https://mendeleev.readthedocs.io/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mendeleev import element\n",
    "\n",
    "extra = {\n",
    "    \"group\": [],\n",
    "    \"period\": [],\n",
    "    \"series\": [],\n",
    "}\n",
    "\n",
    "for symbol in periodic[\"symbol\"]:\n",
    "    el = element(symbol)\n",
    "    group = el.group_id\n",
    "    extra[\"group\"].append(el.group_id)\n",
    "    extra[\"period\"].append(el.period)\n",
    "    extra[\"series\"].append(el.series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e662c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in extra.items():\n",
    "    periodic[key] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997f398",
   "metadata": {},
   "source": [
    "Below, we create a method that will help us make the different plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b29f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_and_loadings(\n",
    "    data,\n",
    "    scores,\n",
    "    loadings,\n",
    "    variables,\n",
    "    idxi=0,\n",
    "    idxj=1,\n",
    "    hue=None,\n",
    "    style=None,\n",
    "    size=None,\n",
    "    palette=None,\n",
    "):\n",
    "    \"\"\"Plot scores and loadings side-by-side.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        constrained_layout=True, ncols=2, figsize=(10, 5)\n",
    "    )\n",
    "\n",
    "    scatter_scores = sns.scatterplot(\n",
    "        x=scores[:, idxi],\n",
    "        y=scores[:, idxj],\n",
    "        data=data,\n",
    "        ax=ax1,\n",
    "        s=80,\n",
    "        hue=hue,\n",
    "        style=style,\n",
    "        size=size,\n",
    "        palette=palette,\n",
    "    )\n",
    "    for i, txt in enumerate(data[\"symbol\"]):\n",
    "        ax1.text(\n",
    "            scores[i, idxi],\n",
    "            scores[i, idxj],\n",
    "            f\"{i+1}({txt})\",\n",
    "            fontsize=\"x-small\",\n",
    "        )\n",
    "    ax1.set(\n",
    "        xlabel=f\"Scores (PLS component {idxi+1})\",\n",
    "        ylabel=f\"Scores (PLS component {idxj+1})\",\n",
    "    )\n",
    "\n",
    "    scatter_loadings = sns.scatterplot(\n",
    "        x=loadings[:, idxi], y=loadings[:, idxj], ax=ax2\n",
    "    )\n",
    "    for i, xi in enumerate(variables):\n",
    "        ax2.text(loadings[i, idxi], loadings[i, idxj], xi, fontsize=\"x-small\")\n",
    "\n",
    "    ax2.set(\n",
    "        xlabel=f\"Rotations (PLS component {idxi+1})\",\n",
    "        ylabel=f\"Rotations (PLS component {idxj+1})\",\n",
    "    )\n",
    "\n",
    "    for axi in (ax1, ax2):\n",
    "        axi.axhline(y=0, ls=\":\", color=\"k\")\n",
    "        axi.axvline(x=0, ls=\":\", color=\"k\")\n",
    "\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55104ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_and_loadings(\n",
    "    periodic,\n",
    "    x_scores,\n",
    "    x_rotations,\n",
    "    x_vars,\n",
    "    hue=\"period\",\n",
    "    palette=\"colorblind\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676b1f8",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.3(b): Are there any trends/groupings or outliers in the scores and what variables can be used to interpret them?\n",
    "\n",
    "The scores plot show \"stripes\" that mirror the periodic system. By coloring according to the period, we see that the \"stripes\" (along component 1) corresponds to the different periods. The elements are also ordered (with the exception of H and He) from low to high atom numbers along the second principal component. This suggest that component 1 describes the electron shell structure, while component 2 could describe nuclear charge.\n",
    "\n",
    "In the loadings, we see strong correlations between the number of electrons, neutrons, and the atomic weight/mass. Along component 1 we see that these variables are also correlated with size-related variables.\n",
    "\n",
    "The different size-related variables are correlated  amongst themselves and with dipole polarizability, which is consistent with the principle that larger atoms tend to be more polarizable. \n",
    "\n",
    "Furthermore, the two electronegativity scales are positively correlated, yet negatively correlated with radii, suggesting that smaller atoms typically exhibit higher electronegativity. The electronegativity value is also correlated with the the effective nuclear charge, suggesting that higher effective nuclear charge results in a stronger attraction on valence electrons.\n",
    "\n",
    "No particular points seem to be outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae076b5",
   "metadata": {},
   "source": [
    "### 5.3(c)\n",
    "\n",
    "**Task: Inspect the scores and rotations for Y by creating 2D scatter plots. Are there any trends/groupings or outliers in the scores? What of the original Y-variables can, if groups/trends are present, be used to interpret these trends?**\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. Assuming that `pls` is the fitted object containing the PLS model, and `X` and `Y` are our raw data, we can get the scores and rotations by:\n",
    "```python\n",
    "x_scores, y_scores = pls.transform(X, y=Y)\n",
    "y_rotations = pls.y_rotations_\n",
    "```\n",
    "\n",
    "2. For the scatter plots, you have two options. To plot the scores and rotations for the two PLS components in two different plots, or in the same plot (as a biplot). The biplot can sometimes help interpretation, but can be crowded if there are many samples and features.\n",
    "\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "1. We use the rotations here instead of the loadings (or weights). This is because the Y-rotations apply directly to the Y data to create the scores. Thus, the rotations tell use more directly the relation between the original variables and the calculated scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be552ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scores, y_scores = pls_periodic.transform(X_peri, y=Y_peri)\n",
    "y_rotations = pls_periodic.y_rotations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_and_loadings(\n",
    "    periodic,\n",
    "    y_scores,\n",
    "    y_rotations,\n",
    "    y_vars,\n",
    "    hue=\"period\",\n",
    "    palette=\"colorblind\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95524a4b",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.3(c): Are there any trends/groupings or outliers in the scores and what variables can be used to interpret them?\n",
    "\n",
    "We still see some grouping similar to the grouping for the X-scores, i.e., \"stripes\" along component 1 that corresponds to the period. Along component 2, elements are ordered according to their atomic radius. However, the alignment is less distinct than in the X-scores, suggesting both components reflect a mix of period and group trends.\n",
    "\n",
    "The atomic radius and first ionization energy are negatively correlated, while density and proton count are positively correlated.  Along component 1, the number of protons and density are positively correlated with the atomic radius which could reflect that in groups, an increase in the proton count will increase the radius. They are negatively correlated along component 2 and this could reflect periods, where an increase in the proton count gives a decrease in the radius.\n",
    "\n",
    "He and Ne (and possibly F) seem to be far away from the other atoms and could be potential outliers. However, their location and order reflect their high first ionization energies (the 3 highest first ionization energies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cca899",
   "metadata": {},
   "source": [
    "### 5.3(d)\n",
    "\n",
    "**Task: Inspect the X-rotations and Y-loadings together. Which of the X-variables could be important for predicting the different Y-variables (answer this by exploring the correlations between the X-variables and the Y-variables).**\n",
    "\n",
    "**Hints:** \n",
    "\n",
    "1. Assuming that `pls` is the fitted object containing the PLS model, we can get the scores for Y by:\n",
    "```python\n",
    "y_loadings = pls.y_loadings_\n",
    "```\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "1. We use the X-rotations ($R$) and Y-loadings ($Q$) because they help us understand the relationships between the X-variables and the Y-variables in the PLS model. The PLS model $Y = XB = XRQ^T$ shows that the regression coefficients ($B$) can be decomposed into the product of $R$ and $Q^T$. Therefore, plotting $R$ and $Q$ together helps us investigate correlations captured by the PLS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_loadings = pls_periodic.y_loadings_\n",
    "x_loadings = pls_periodic.x_loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "\n",
    "scatter_loadings = sns.scatterplot(\n",
    "    x=x_rotations[:, 0], y=x_rotations[:, 1], ax=ax\n",
    ")\n",
    "for i, txt in enumerate(x_vars):\n",
    "    ax.text(x_rotations[i, 0], x_rotations[i, 1], txt, fontsize=\"small\")\n",
    "\n",
    "scatter_loadings = sns.scatterplot(\n",
    "    x=y_loadings[:, 0], y=y_loadings[:, 1], ax=ax, color=\"red\"\n",
    ")\n",
    "\n",
    "for i, txt in enumerate(y_vars):\n",
    "    ax.text(\n",
    "        y_loadings[i, 0],\n",
    "        y_loadings[i, 1],\n",
    "        txt,\n",
    "        fontsize=\"small\",\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    xlabel=f\"Loadings/Rotations (PLS component 1)\",\n",
    "    ylabel=f\"Loadings/Rotations (PLS component 2)\",\n",
    ")\n",
    "\n",
    "ax.axhline(y=0, ls=\":\", color=\"k\")\n",
    "ax.axvline(x=0, ls=\":\", color=\"k\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ad5bb",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.3(d): What X-variables seem important for predicting Y and what variables are correlated?\n",
    "\n",
    "The first ionization energy is positively correlated with the electronegativity, the proton count (and density) are positively correlated with the electron count, and the atomic radius is positively correlated with the other radii. The atomic radius is also negatively correlated with the electronegativity. We can visualise these correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(constrained_layout=True, ncols=4, figsize=(12, 3))\n",
    "sns.scatterplot(\n",
    "    data=periodic,\n",
    "    x=\"electronegativity allred-rochow\",\n",
    "    y=\"first_ionization\",\n",
    "    ax=axes[0],\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=periodic,\n",
    "    x=\"electrons\",\n",
    "    y=\"protons\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=periodic,\n",
    "    x=\"electrons\",\n",
    "    y=\"density\",\n",
    "    ax=axes[2],\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=periodic,\n",
    "    x=\"electronegativity allred-rochow\",\n",
    "    y=\"atomic_radius\",\n",
    "    ax=axes[3],\n",
    ")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a21689",
   "metadata": {},
   "source": [
    "This suggest that we could potentially create a simplified model with just two x-variables, the number of electrons and the electronegativity. Let us check and compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_peri_hat = pls_periodic.predict(X_peri)\n",
    "print(\"R² (all X variables):\", r2_score(Y_peri, Y_peri_hat))\n",
    "\n",
    "X_peri2 = StandardScaler().fit_transform(\n",
    "    periodic[[\"electrons\", \"electronegativity allred-rochow\"]].to_numpy()\n",
    ")\n",
    "model2 = PLSRegression(n_components=2)\n",
    "model2.fit(X_peri2, Y_peri)\n",
    "Y_peri_hat_2 = model2.predict(X_peri2)\n",
    "print(\n",
    "    \"R² (X: electrons and electronegativity):\", r2_score(Y_peri, Y_peri_hat_2)\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(constrained_layout=True, ncols=4, figsize=(12, 3))\n",
    "\n",
    "for i, yvar in enumerate(y_vars):\n",
    "    axes[i].scatter(Y_peri[:, i], Y_peri_hat[:, i])\n",
    "    axes[i].scatter(Y_peri[:, i], Y_peri_hat_2[:, i])\n",
    "    axes[i].set_title(f\"Variable: {yvar}\", loc=\"left\")\n",
    "    axes[i].set_xlabel(\"Observed (y)\")\n",
    "    axes[i].set_ylabel(\"Predicted (ŷ)\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9611c6",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a31c4b",
   "metadata": {},
   "source": [
    "## A. Leave-one-out cross-validation\n",
    "\n",
    "In Leave-one-out cross-validation (LOOCV), we first pick one sample,\n",
    "measurement number $j$, and we fit the model using the $n-1$ other points\n",
    "(all points except $j$). After the fitting, we check how well the model can predict\n",
    "measurement $j$ by calculating the difference between the\n",
    "measured ($y_j$) and predicted ($\\tilde{y}_j$) value. This difference, $r_j = y_{j} - \\tilde{y}_j$, is\n",
    "called the predicted residual, and it tells us the error we just made.\n",
    "\n",
    "There is nothing special about picking point $j$, and we can try all possibilities\n",
    "of leaving one point out, fitting the model using the remaining $n-1$\n",
    "measurements, and predicting the value we left out.\n",
    "After doing this for all possibilities, we have fitted the model\n",
    "$n$ times and calculated $n$ predicted residuals. The mean squared error (obtained from the squared\n",
    "residuals), $\\mathrm{MSE}_{\\mathrm{CV}}$, can then be used\n",
    "to estimate the error in the model,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{MSE}_{\\mathrm{CV}} = \\frac{1}{n} \\sum_{i=1}^{n} r_i^2 =  \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\tilde{y}_i)^2,\n",
    "\\end{equation}\n",
    "\n",
    "where $y_i$ is the measured $y$ in experiment $i$, and $\\tilde{y}_i$ is the\n",
    "predicted $y$, using a model which was fitted using all points *except* $y_i$.\n",
    "\n",
    "For a polynomial fitting, there is an alternative to refitting the model $n$ times. In fact,\n",
    "we can show that for polynomial fitting, the mean squared error can\n",
    "be obtained by,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{MSE}_{\\mathrm{CV}} = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\tilde{y}_i)^2 =\n",
    "\\frac{1}{n}\\sum_{i=1}^{m} \\left(\\frac{y_i - \\hat{y}_i}{1 - h_{ii}} \\right)^2,\n",
    "\\end{equation}\n",
    "\n",
    "where the $\\hat{y}_i$'s are predicted values using the\n",
    "model fitted with *all data points*,\n",
    "and $h_{ii}$ is the $i$'th diagonal element of the\n",
    "$\\mathbf{H}$ matrix (the projection matrix,\n",
    "see Eq.(4.49) on page 49 in our textbook),\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H} =\n",
    "\\mathbf{X} \n",
    "\\left( \n",
    "  \\mathbf{X}^\\mathrm{T} \\mathbf{X}\n",
    "\\right)^{-1}\n",
    "\\mathbf{X}^\\mathrm{T} = \\mathbf{X} \\mathbf{X}^+,\n",
    "\\end{equation}\n",
    "\n",
    "Note the difference between $\\hat{y}_i$ and $\\tilde{y}_i$, and the\n",
    "fact that we  do not have to do the\n",
    "refitting(!) to obtain the $\\mathrm{MSE}_{\\mathrm{CV}}$.\n",
    "\n",
    "When you calculate $\\mathrm{MSE}_{\\mathrm{CV}}$, use one of the two approaches above or both\n",
    "if you want to see if they give the same answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The examples below assume that the matrix X is called X_temp\n",
    "# and that y is stored in the variable pressure.\n",
    "\n",
    "# Example 1 of LOOCV:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# scikit-learn has a method to pick out samples for leave-one-out:\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "error = []\n",
    "# Split the X-data in X_temp into training and testing:\n",
    "for train_index, test_index in loo.split(X_temp):\n",
    "    # train_index = index of samples to use for training\n",
    "    # test_index = index of samples to use for testing\n",
    "    # Pick out samples (for training and testing):\n",
    "    X_train, X_test = X_temp[train_index], X_temp[test_index]\n",
    "    y_train, y_test = pressure[train_index], pressure[test_index]\n",
    "    # Fit a new model with the training set:\n",
    "    model = LinearRegression(fit_intercept=True).fit(X_train, y_train)\n",
    "    # Predict y for the test set:\n",
    "    y_hat = model.predict(X_test)\n",
    "    # Compare the predicted y values in the test set with the measured ones:\n",
    "    error.append((y_test - y_hat) ** 2)\n",
    "rmsecv_1 = np.sqrt(np.mean(error))\n",
    "print(f\"RMSECV = {rmsecv_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aaa71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 of LOOCV:\n",
    "\n",
    "# scikit-learn has a method for leave-one-out selection, and a method for\n",
    "# cross-validation. And these two can be combined:\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "# Create \"empty\" model for fitting:\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "# Run cross-validation, where we select testing and training with LeaveOneOut:\n",
    "scores = cross_val_score(\n",
    "    model, X_temp, pressure, scoring=\"neg_mean_squared_error\", cv=LeaveOneOut()\n",
    ")\n",
    "rmsecv_2 = np.sqrt(np.mean(-scores))\n",
    "print(f\"RMSECV = {rmsecv_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3 of LOOCV:\n",
    "\n",
    "# We calculate the H matrix and use that:\n",
    "# OBS! First, a detail that is easy to miss; The X used for H includes the column of ones!\n",
    "X_matrix = np.column_stack((np.ones_like(temperature), temperature))\n",
    "H = X_matrix @ np.linalg.pinv(X_matrix)\n",
    "hii = np.diagonal(H)\n",
    "residuals_loo = (pressure - pressure_hat) / (1 - hii)\n",
    "rmsecv_3 = np.sqrt(np.mean(residuals_loo**2))\n",
    "print(f\"RMSECV = {rmsecv_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24bdc90",
   "metadata": {},
   "source": [
    "## Your feedback for Exercise 5\n",
    "\n",
    "1. **Time & Difficulty:**\n",
    "* Length (1=too short, 5=too long): 1  2  3  4  5\n",
    "* Difficulty (1=too easy, 5=too difficult): 1  2  3  4  5\n",
    "* Most challenging part: ________________________\n",
    "\n",
    "2. **Code Examples:**\n",
    "* More or less example code?  More  Less  About Right\n",
    "* Areas where more examples would be helpful: ________________________\n",
    "\n",
    "3. **Errors/Inconsistencies:** Did you encounter any?  Yes  No  If yes, please describe: ________________________\n",
    "    \n",
    "4. **Suggestions:** How could this exercise be improved? ________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
